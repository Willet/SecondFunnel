---
- name: "Check for Existing EC2 Instances"
  hosts: "building_{{app_environment}}"
  tasks:
    - name: Gather facts
      action: ec2_facts
      tags: ami
    - name: Add existing instance to launched groups
      local_action: add_host hostname="{{ansible_ec2_public_hostname}}" groups="webservers,{{app_environment}},launched"
      register: existing_instance
      tags: ami

- name: "Launch EC2 instance to image"
  hosts: localhost
  connection: local
  gather_facts: False # so the groups don't change if existing host was running above
  vars_files:
    - "group_vars/{{app_environment}}.yml"
  tasks:
    - name: "Launch EC2 instance"
      action:
        module: ec2
        aws_access_key: "{{aws_access_key_id}}"
        aws_secret_key: "{{aws_secret_key}}"
        image: "{{ aws_base_image }}"
        instance_type: "{{aws_instance_type}}"
        state: present
        region: "{{ aws_region }}"
        key_name: "{{ aws_sshkey_name }}"
        group: "{{aws_security_groups}}"
        wait: true
        instance_tags:
          Name: "{{aws_name}}-building"
          Environment: "{{app_environment}}"
          Building: "{{app_environment}}-AMI"
      register: ec2
      when: "'launched' not in groups"

    - name: Wait for SSH to come up
      local_action: wait_for host="{{item.public_dns_name}}" port=22 delay=20 timeout=320 state=started
      with_items: ec2.instances
      when: "'launched' not in groups"

    # NOTE: this must be the last of the tasks, otherwise the when condition will fail (since it adds the host)
    - name: Add new instance to host groups
      local_action: add_host hostname="{{item.public_dns_name}}" groups="webservers,{{app_environment}},launched"
      with_items: ec2.instances
      when: "'launched' not in groups"

- name: "Bootstrap Servers"
  hosts: launched
  roles:
    - common
    - aws_tools

- name: "Setup Servers"
  hosts: launched
  remote_user: "{{common_user}}"
  roles:
    - { role: phantomjs, tags: phantomjs, sudo: true }
    - { role: newrelic, tags: newrelic, sudo: true, when: app_environment != 'vagrant' }
    - { role: monit, tags: monit, sudo: true }
    - { role: nginx, tags: nginx, sudo: true }
    - { role: node, tags: node }
    - { role: pgbouncer, tags: pgbouncer, sudo: true }
    - { role: venv, tags: venv }
    - { role: uwsgi, tags: uwsgi }
    - { role: web, tags: web_application }

- name: "Create AMI, Build Launch Config, and Terminate instances"
  hosts: launched
  tasks:
    - name: Gather facts
      action: ec2_facts
      tags: ami
    - name: "Save the AMI"
      local_action:
        module: ec2_ami
        aws_access_key: "{{aws_access_key_id}}"
        aws_secret_key: "{{aws_secret_key}}"
        name: "{{aws_ami.name}}"
        description: "{{aws_ami.description}}"
        region: "{{aws_region}}"
        instance_id: "{{ansible_ec2_instance_id}}"
        wait: yes
      tags: ami
      register: ami_built

    - debug:
        msg: "Register AMI: {{ami_built}}"

    - name: "Terminate instances that were previously launched"
      local_action:
        module: ec2
        aws_access_key: "{{aws_access_key_id}}"
        aws_secret_key: "{{aws_secret_key}}"
        state: "absent"
        instance_ids: "{{ ansible_ec2_instance_id }}"
        region: "{{aws_region}}"
      tags: ami

    - name: "Create Launch Configuration For AMI"
      local_action:
        module: ec2_lc
        aws_access_key: "{{aws_access_key_id}}"
        aws_secret_key: "{{aws_secret_key}}"
        region: "{{aws_region}}"
        name: "{{aws_lc.name}}"
        user_data: "{{aws_lc.user_data}}"
        security_groups: "{{aws_security_groups}}"
        instance_type: "{{aws_instance_type}}"
        key_name: "{{aws_server_sshkey_name}}"
        image_id: "{{ami_built.image_id}}"
      register: lc_built

    - debug:
        msg: "Registered Launch Configuration: {{lc_built}}"

- name: "Create Load Balancer"
  hosts: localhost
  vars_files:
    - "group_vars/{{app_environment}}.yml"
  tasks:
    - name: "Grab Load Balancer (or create if necessary)"
      local_action:
        module: ec2_elb_lb
        aws_access_key: "{{aws_access_key_id}}"
        aws_secret_key: "{{aws_secret_key}}"
        name: "{{aws_lb.name}}"
        state: present
        region: "{{aws_region}}"
        zones: "{{aws_lb.zones}}"
        listeners:
          - protocol: http
            load_balancer_port: 80
            instance_port: 80
        health_check: "{{aws_lb.healthcheck}}"
        connection_draining_timeout: 60
      register: load_balancer

- name: "Setup auto-scaling group, scaling policies"
  hosts: localhost
  vars_files:
    - "group_vars/{{app_environment}}.yml"
  tasks:
    - name: "Create Auto Scaling Group (for AMI just built)"
      local_action:
        module: ec2_asg
        aws_access_key: "{{aws_access_key_id}}"
        aws_secret_key: "{{aws_secret_key}}"
        region: "{{aws_region}}"
        name: "{{aws_asg.name}}"
        launch_config_name: "{{aws_lc.name}}"
        load_balancers: "{{aws_lb.name}}"
        availability_zones: "{{aws_availability_zones}}"
        health_check_type: "{{aws_asg.health_check_type}}"
        min_size: "{{aws_asg.min_size}}"
        max_size: "{{aws_asg.max_size}}"
        desired_capacity: "{{aws_asg.desired_capacity}}"
        tags:
          - Name: "{{aws_name}}"
            Environment: "{{app_environment}}"
            propagate_at_launch: true

      register: asg_built

    - debug:
        msg: "Registered AutoScalingGroup: {{asg_built}}"

    - name: Create scale up policy
      local_action:
        module: ec2_scaling_policy
        aws_access_key: "{{aws_access_key_id}}"
        aws_secret_key: "{{aws_secret_key}}"
        state: present
        region: "{{aws_region}}"
        name: "{{aws_name}}-scaling-group-High-CPU-Utilization"
        adjustment_type: "ChangeInCapacity"
        asg_name: "{{aws_name}}-scaling-group"
        scaling_adjustment: 1
        min_adjustment_step: 1
        cooldown: 120
      register: scale_up_policy

    - debug:
        msg: "Registered scale_up_policy: {{ scale_up_policy }}"

    - name: Create scale down policy
      local_action:
        module: ec2_scaling_policy
        aws_access_key: "{{aws_access_key_id}}"
        aws_secret_key: "{{aws_secret_key}}"
        state: present
        region: "{{aws_region}}"
        name: "{{aws_name}}-scaling-group-CPU-Utilization"
        adjustment_type: "ChangeInCapacity"
        asg_name: "{{aws_name}}-scaling-group"
        scaling_adjustment: -1
        min_adjustment_step: 1
        cooldown: 120
      register: scale_down_policy

    - debug:
        msg: "Registered scale_down_policy: {{ scale_down_policy }}"

    - name: Create scale-up, high-cpu alarm
      local_action:
        module: ec2_metric_alarm
        aws_access_key: "{{aws_access_key_id}}"
        aws_secret_key: "{{aws_secret_key}}"
        state: present
        region: "{{ aws_region }}"
        name: "{{aws_name}}-cpu-high"
        metric: "CPUUtilization"
        namespace: "AWS/EC2"
        statistic: "Average"
        comparison: ">="
        threshold: 80.0
        period: 180
        evaluation_periods: 2
        unit: "Percent"
        description: "Scale-up if CPU > 80% for 6 minutes"
        dimensions: {"AutoScalingGroupName":"{{aws_asg.name}}"}
        alarm_actions: ["{{ scale_up_policy.arn }}"]
      when: scale_up_policy.arn is defined

    - name: Create scale-down, low-cpu alarm
      local_action:
        module: ec2_metric_alarm
        aws_access_key: "{{aws_access_key_id}}"
        aws_secret_key: "{{aws_secret_key}}"
        state: present
        region: "{{ aws_region }}"
        name: "{{aws_name}}-cpu-low"
        metric: "CPUUtilization"
        namespace: "AWS/EC2"
        statistic: "Average"
        comparison: "<="
        threshold: 50.0
        period: 300
        evaluation_periods: 2
        unit: "Percent"
        description: "Scale-down if CPU < 50% for 10 minutes"
        dimensions: {"AutoScalingGroupName":"{{aws_asg.name}}"}
        alarm_actions: ["{{ scale_down_policy.arn }}"]
      when: scale_down_policy.arn is defined
